library(ggplot2)
library(dplyr)
library(tidyr)
library(plyr)

library(foreign)
library(nnet)
library(reshape2)

# Inputing data into R and naming data as old_data
old_data <- read.csv('Plan_Crosswalk_2014_2015.csv', stringsAsFactors=FALSE)

# retrieving column names from old_data
names(old_data)

head(old_data)

# code run to show no. of dental plans only in the dataset
table(old_data$DentalPlan)

# Since we will conduct study on QHP plans only, we will eliminate dental plans from the dataset
old_data <- subset(old_data,DentalPlan != 'Y')

#Using library tidyr, we unite columns "Plan_Id2014 & FIPSCODE" into a column "ID"  which will be a reference ID
old_data <- old_data %>% unite("ID",PlanID_2014,FIPSCode, sep = "-")


# Here, we are plotting level of insurance coverage for 2014
ggplot(aes(x=MetalLevel_2014),data = old_data) + geom_bar()
ggsave(filename = "MetalLevel2014.jpg")

# Here, we are plotting level of insurance coverage for 2015
ggplot(aes(x=MetalLevel_2015),data = old_data) + geom_bar()
ggsave(filename = "MetalLevel2015.jpg")

# Here, we are plotting reasons for crosswalk for plans that included crosswalk
ggplot(aes(x=ReasonForCrosswalk),data = subset(old_data,CrosswalkLevel != 0)) + geom_bar()
ggsave(filename = "reasonforcrosswalk.jpg")


# Plotting difference of metal level for 2014 & 2015. 1 means the same metal level. 2 means diff metal level.
old_data$diffmetal_level <- ifelse(old_data$MetalLevel_2014 == old_data$MetalLevel_2015,1,0)

table(old_data$diffmetal_level)

names(old_data)

# Check if crosswalk level is same as reasons for crosswalk level
old_data$diff_crosswalk <- ifelse(old_data$CrosswalkLevel == old_data$ReasonForCrosswalk ,1,0)

table(old_data$diff_crosswalk)


######################################
####  Prediction Modelling No.1

## The predictor variables are MultistatePaln_2014, MetalLevel_2014 & CrosswalkLevel

## Below we are getting some descriptive statistics in relationship with the dependant variable, ReasonForCrosswalk

with(old_data, table(MultistatePlan_2014, ReasonForCrosswalk))

with(old_data, table(MetalLevel_2014, ReasonForCrosswalk))

with(old_data, table(CrosswalkLevel, ReasonForCrosswalk))


## Here, we convert the values for ReasonoForCrosswalk to factors

old_data$Factors_RFC <- as.factor(old_data$ReasonForCrosswalk)

str(old_data)


## Using value of 0 which is (Renewing the same product/plan combination using the same 2014 Plan ID) as base reference for the multinomial logistic model
old_data$RFC2 <- relevel(old_data$Factors_RFC, ref = '0')

test <- multinom(RFC2 ~ MultistatePlan_2014 + MetalLevel_2014 + CrosswalkLevel, data = old_data)

## After 100 iterations, our error are 59,910

summary(test)

## running prediction on our data using the 'test' model
predict(test,old_data,type ='prob')


## Here, we show the misclassification error
cm <- table(predict(test),old_data$Factors_RFC)
cm

## Below, we calculate the accuracy of the 'test' model :

1 - sum(diag(cm))/sum(cm)

## the output is 0.183 which means there is (1-18.3)% = 81.7 % accuracy

## 2 tailed z test
z <- summary(test)$coefficients/summary(test)$standard.errors
p <- (1 - pnorm(abs(z),0,1))*2
p



######################################
####  Prediction Modelling No.2

## we remove MultistatePlan_2014

test2 <- multinom(RFC2 ~ MetalLevel_2014 + CrosswalkLevel, data = old_data)

# after doing 10 iterations, our error is 60,050
summary(test2)

## running prediction on our data using the 'test2' model
predict(test2,old_data,type ='prob')

## Here, we show the misclassification error
cm2 <- table(predict(test2),old_data$Factors_RFC)
cm2

## Below, we calculate the accuracy of the 'test2' model :

1 - sum(diag(cm2))/sum(cm2)

## the output is 0.183 which means there is (1-18.3)% = 81.7 % accuracy

## 2 tailed z test
z <- summary(test2)$coefficients/summary(test2)$standard.errors
p <- (1 - pnorm(abs(z),0,1))*2
p


